{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEIRS model with Cost Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS:\n",
    "\n",
    "* Update Betas in list based on infection chance of the occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. File Setup\n",
    "Start here if `worker_data_final.pickle` is not in the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from seirsplus.models import *\n",
    "import networkx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pandas dataframe from excel file\n",
    "filePath = 'Work_Context.xlsx'\n",
    "worker_data = pd.read_excel(filePath)\n",
    "# Save file so it does not have to be recompiled\n",
    "with open('pickles/worker_data.pickle', 'wb') as file:\n",
    "    pickle.dump(worker_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'national_M2019_dl.xlsx'\n",
    "occupation_data = pd.read_excel(filePath)\n",
    "# Save file so it does not have to be recompiled\n",
    "with open('pickles/occupation_data.pickle', 'wb') as file:\n",
    "    pickle.dump(occupation_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/occupation_data.pickle', 'rb') as file:\n",
    "    occupation_data = pickle.load(file)\n",
    "with open('pickles/worker_data.pickle', 'rb') as file:\n",
    "    worker_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse Data (Dept. of Labor)\n",
    "\n",
    "The Depertment of Labor data contains a whole swath of contextual information about each occupation within its database. The only features were are interested in are the metrics on a job's `Exposed to Disease or Infections` and `Physical Proximity` measures. These can be found in the `worker_data` object in this notebook and here (https://www.onetcenter.org/database.html#individual-files). `Employment` and `Annual Income` can be found in the `occupation_data` object and this website (https://www.bls.gov/oes/current/oes_nat.htm#11-0000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" WORKER_DATA Filter rows based on relevant characteristics \"\"\"\n",
    "relevant_elements = [\"Exposed to Disease or Infections\", \"Physical Proximity\"]\n",
    "characteristics = worker_data['Element Name']\n",
    "\n",
    "worker_data_filtered = worker_data.loc[\n",
    "    (worker_data['Element Name'].isin(relevant_elements)) # filter on characteristics\n",
    "    & (worker_data['Scale ID'] == 'CX')] # filter on score (out of 5)\n",
    "\n",
    "worker_data_filtered = worker_data_filtered.filter(items=['O*NET-SOC Code','Title', 'Element Name', 'Data Value'])\n",
    "worker_data_filtered[\"O*NET-SOC Code\"] = worker_data_filtered[\"O*NET-SOC Code\"].apply(lambda x: x.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build crosslisting between worker_data and occupation_data based on occ_code\n",
    "occupation_list = worker_data_filtered['O*NET-SOC Code']\n",
    "# Strip CC in AAA-BBBB.CC format of the job identifier in the worker_data Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" OCCUPATION DATA Filter rows based on relevant characteristics \"\"\"\n",
    "# Get population and income data for occupations\n",
    "occupation_data_filtered = occupation_data.loc[\n",
    "    (occupation_data['occ_code'].isin(occupation_list))] # filter on characteristics\n",
    "\n",
    "occupation_data_filtered = occupation_data_filtered.filter(items=['occ_code','occ_title','tot_emp','a_mean'])\n",
    "occupation_data_filtered = occupation_data_filtered.rename(columns={'occ_title':'Title', 'tot_emp':'Employment','a_mean':'Annual Income', 'occ_code':'O*NET-SOC Code'})\n",
    "\n",
    "# general_population = occupation_data_filtered.iloc[0][2] # first entry of the Employment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   O*NET-SOC Code                                Title  Employment  \\\n4         11-1011                     Chief Executives      205890   \n6         11-1021      General and Operations Managers     2400280   \n11        11-2011  Advertising and Promotions Managers       25100   \n13        11-2021                   Marketing Managers      263680   \n14        11-2022                       Sales Managers      402600   \n\n   Annual Income  \n4         193850  \n6         123030  \n11        141890  \n13        149200  \n14        141690  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>O*NET-SOC Code</th>\n      <th>Title</th>\n      <th>Employment</th>\n      <th>Annual Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>11-1011</td>\n      <td>Chief Executives</td>\n      <td>205890</td>\n      <td>193850</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>11-1021</td>\n      <td>General and Operations Managers</td>\n      <td>2400280</td>\n      <td>123030</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11-2011</td>\n      <td>Advertising and Promotions Managers</td>\n      <td>25100</td>\n      <td>141890</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>11-2021</td>\n      <td>Marketing Managers</td>\n      <td>263680</td>\n      <td>149200</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>11-2022</td>\n      <td>Sales Managers</td>\n      <td>402600</td>\n      <td>141690</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "occupation_data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    O*NET-SOC Code                            Title  \\\n120        11-1011                 Chief Executives   \n168        11-1011                 Chief Executives   \n458        11-1011    Chief Sustainability Officers   \n506        11-1011    Chief Sustainability Officers   \n796        11-1021  General and Operations Managers   \n\n                         Element Name  Data Value  \n120                Physical Proximity        2.73  \n168  Exposed to Disease or Infections        1.72  \n458                Physical Proximity        2.92  \n506  Exposed to Disease or Infections        1.12  \n796                Physical Proximity        3.21  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>O*NET-SOC Code</th>\n      <th>Title</th>\n      <th>Element Name</th>\n      <th>Data Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>120</th>\n      <td>11-1011</td>\n      <td>Chief Executives</td>\n      <td>Physical Proximity</td>\n      <td>2.73</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>11-1011</td>\n      <td>Chief Executives</td>\n      <td>Exposed to Disease or Infections</td>\n      <td>1.72</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>11-1011</td>\n      <td>Chief Sustainability Officers</td>\n      <td>Physical Proximity</td>\n      <td>2.92</td>\n    </tr>\n    <tr>\n      <th>506</th>\n      <td>11-1011</td>\n      <td>Chief Sustainability Officers</td>\n      <td>Exposed to Disease or Infections</td>\n      <td>1.12</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>11-1021</td>\n      <td>General and Operations Managers</td>\n      <td>Physical Proximity</td>\n      <td>3.21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "worker_data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include professions overlap between the 2 tables (1-1)\n",
    "\n",
    "worker_data_filtered.head()\n",
    "# merged_inner = pd.merge(left=survey_sub, right=species_sub, left_on='species_id', right_on='species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Reformat Dataframe to include the below features \"\"\"\n",
    "# Title, Context Score 1, Context Score 2\n",
    "dataframes = []\n",
    "for element in relevant_elements:\n",
    "    df = worker_data_filtered.copy()\n",
    "    df = df[characteristics == element]\n",
    "    df = df.drop(columns=['Element Name'])\n",
    "    df = df.rename(columns={'Data Value': element})\n",
    "    dataframes.append(df)\n",
    "\n",
    "from functools import reduce\n",
    "worker_data_final = reduce(lambda df1,df2: pd.merge(df1,df2,on=['Title', 'O*NET-SOC Code'], how='left'), dataframes)\n",
    "\n",
    "# Merge with Population data\n",
    "# worker_data_final = pd.merge(worker_data_final, )\n",
    "worker_data_final = pd.merge(left=worker_data_final, right=occupation_data_filtered, left_on=['Title','O*NET-SOC Code'], right_on=['Title','O*NET-SOC Code'])\n",
    "worker_data_final = worker_data_final.drop(columns=['O*NET-SOC Code'])\n",
    "worker_data_final['Employment'] =  worker_data_final['Employment'].apply(lambda a: int(a)) \n",
    "#  worker_data_final['Annual Income'] = worker_data_final['Annual Income'].apply(lambda a: int(a))\n",
    "worker_data_final.to_csv('worker_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "101259780"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "general_population = worker_data_final['Employment'].sum()\n",
    "general_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file so it does not have to be recompiled\n",
    "with open('pickles/worker_data_final.pickle', 'wb') as file:\n",
    "    pickle.dump(worker_data_final, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Barabasi-Albert Graph generation\n",
    "\n",
    "Barabasi-Albert Graphs are \n",
    "\n",
    "A unique graph will be generated for each occupation listed by the Department of Labor. The number of nodes (`n`) will be determined by the number of individuals of that occupation in the population. The number of connections within the graph (`m`) will be determined by one's physical proximity to others in the workplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the pickle of the relevant data \n",
    "with open('pickles/worker_data_final.pickle', 'rb') as file:\n",
    "    worker_data_final = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population = 10000\n",
    "avg_interactions_p_day = 17 # (https://www.researchgate.net/figure/Daily-average-number-of-contacts-per-person-in-age-group-j-The-average-number-of_fig2_228649013)\n",
    "\n",
    "# general_population = 155760000 # 155.76 milion employed individuals in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                 Title  Exposed to Disease or Infections  \\\n0                     Chief Executives                              1.72   \n1      General and Operations Managers                              1.56   \n2  Advertising and Promotions Managers                              1.03   \n3                   Marketing Managers                              1.07   \n4                       Sales Managers                              1.13   \n\n   Physical Proximity  Employment Annual Income  \n0                2.73      205890        193850  \n1                3.21     2400280        123030  \n2                2.82       25100        141890  \n3                2.89      263680        149200  \n4                2.91      402600        141690  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Exposed to Disease or Infections</th>\n      <th>Physical Proximity</th>\n      <th>Employment</th>\n      <th>Annual Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chief Executives</td>\n      <td>1.72</td>\n      <td>2.73</td>\n      <td>205890</td>\n      <td>193850</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>General and Operations Managers</td>\n      <td>1.56</td>\n      <td>3.21</td>\n      <td>2400280</td>\n      <td>123030</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Advertising and Promotions Managers</td>\n      <td>1.03</td>\n      <td>2.82</td>\n      <td>25100</td>\n      <td>141890</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Marketing Managers</td>\n      <td>1.07</td>\n      <td>2.89</td>\n      <td>263680</td>\n      <td>149200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sales Managers</td>\n      <td>1.13</td>\n      <td>2.91</td>\n      <td>402600</td>\n      <td>141690</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "worker_data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Build a graph for each occupation \n",
    "\n",
    "# determine 'n' based on population data\n",
    "listOfNodes = [] # a list of all the nodes across all graphs\n",
    "numPasses = 0\n",
    "for _, row in worker_data_final.iterrows():\n",
    "    title        = row['Title']\n",
    "    numNodes     = int((row['Employment'] / general_population)*total_population)\n",
    "    interaction  = int(row['Physical Proximity']) # TODO: Determine an effective scaling factor -> range(0, 5)\n",
    "    # print(numNodes, interaction)\n",
    "    if numNodes <= interaction:\n",
    "        continue\n",
    "    baseGraph    = networkx.barabasi_albert_graph(n=numNodes, m=interaction)\n",
    "    for node in baseGraph.nodes:\n",
    "        listOfNodes.append((title, len([n for n in baseGraph[node]])))\n",
    "    numPasses+=1\n",
    "    # print(numPasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9441"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(listOfNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/listOfNodes.pickle', \"wb\") as file:\n",
    "    pickle.dump(listOfNodes, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merging Barabasi-Albert Graphs\n",
    "\n",
    "This mechanism of merging the Barabasi Graphs of different occupations follows the research here (https://www.researchgate.net/publication/271200973_On_Merging_and_Dividing_of_Barabasi-Albert-Graphs)\n",
    "\n",
    "Below is an implementation of the `Node-Degree-Order Merge` which runs in `O(n*log(n))`.\n",
    "\n",
    "This method orders the nodes by the number of connections they contain across all of the graphs being merged. A new graph is then developed using the Barabasi-Albert model by inserting these nodes in order. The analogy this paper uses to this scenario is like a \"student graduating from school and going to university\". In our model, the number of connections is directly correlated with the physical proximity to others. This merging technique is a mechanism to more effectively scale the physical proximity metric proportionally across occupations. The \"graduation\" can be considered a transition of popularity (in one's number of interactions) from within an occupation, to a larger population.\n",
    "\n",
    "The aggregate Barabsi-Albert graph will have parameters reflecting the total population. The number of nodes (`n`) will be the total population relative to the populations of each occupation. The number of connections per iteration (`m`) will be relative to the average number of interactions a given individual will have in a day. Nodes are 0 indexed within `listOfNodes`, so each individual (and their occupation) is easy to track within the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listOfNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/listOfNodes.pickle', \"rb\") as file:\n",
    "    listOfNodes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "' listOfNodes and full_graph.nodes has a 1-1 translation '"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "listOfNodes.sort(key=lambda x: x[1], reverse=True) # list of Nodes in descending order, sorted by number of connections\n",
    "\n",
    "full_graph    = networkx.barabasi_albert_graph(n=len(listOfNodes), m=avg_interactions_p_day)\n",
    "\"\"\" listOfNodes and full_graph.nodes has a 1-1 translation \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Integration with SEIRS\n",
    "\n",
    "One factor that we have not taken into account yet is the exposure that one has to the disease (Covid-19). Within the SEIRS model, this directly corresponds to the `beta` or `rate of transmission` parameter. We can map a rate of transmission to each node in our Barabasi graph and dynamically modify them in simulations in future sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_normal     = custom_exponential_graph(full_graph, scale=100)\n",
    "# Social distancing interactions:\n",
    "G_distancing = custom_exponential_graph(full_graph, scale=10)\n",
    "# Quarantine interactions:\n",
    "G_quarantine = custom_exponential_graph(full_graph, scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "betas = [] # TODO: set up betas for each occupation\n",
    "for individual in listOfNodes:\n",
    "    title, _        = individual\n",
    "    infection       = worker_data_final.loc[worker_data_final['Title'] == title]['Exposed to Disease or Infections']\n",
    "    betas.append(infection*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEIRSNetworkModel(G=G_normal, beta=0.155, sigma=1/5.2, gamma=1/12.39, mu_I=0.0004, p=0.5,\n",
    "                          Q=G_quarantine, beta_D=0.155, sigma_D=1/5.2, gamma_D=1/12.39, mu_D=0.0004,\n",
    "                          theta_E=0.02, theta_I=0.02, phi_E=0.2, phi_I=0.2, psi_E=1.0, psi_I=1.0, q=0.5,\n",
    "                          initI=10)\n",
    "                          \n",
    "with open(\"pickles/SEIRS_model.pickle\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Running Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/worker_data_final.pickle', 'rb') as file:\n",
    "    worker_data_final = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/listOfNodes.pickle', \"rb\") as file:\n",
    "    listOfNodes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual():\n",
    "    def __init__(self, id, occupation, income, numConn):\n",
    "        self.id = id\n",
    "        self.occupation = occupation\n",
    "        self.income = income\n",
    "        self.savings = 0.2*income\n",
    "        self.number_connections = numConn\n",
    "        self.connections = [] # list of individuals with an active connection\n",
    "        self.pendingActiveConnection = 0 # pending number of connections the individual is attempting to have\n",
    "    def payments(self, amount):\n",
    "        self.income = int(self.income)\n",
    "        if self.income == '*':\n",
    "            return\n",
    "        self.income += amount\n",
    "    def cost(self, amount):\n",
    "        self.income = int(self.income)\n",
    "        if self.income == '*':\n",
    "            return\n",
    "        self.income -= amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initIndividuals():\n",
    "    listOfIndividuals = [Individual(id, occupation, worker_data_final.loc[worker_data_final['Title'] == occupation]['Annual Income'],  numConn) for id, (occupation, numConn) in enumerate(listOfNodes)]\n",
    "    print(\"Set up the list!\")\n",
    "    for edge in list(model.G.edges):\n",
    "        a, b = edge\n",
    "        listOfIndividuals[a].connections.append(b)\n",
    "        listOfIndividuals[b].connections.append(a)\n",
    "    print(\"Set up the edge connections!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Set up the list!\nSet up the edge connections!\n"
    }
   ],
   "source": [
    "initIndividuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'listOfIndividuals' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-badab0abefed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pickles/individuals.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistOfIndividuals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'listOfIndividuals' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"pickles/individuals.pickle\", \"wb\") as file:\n",
    "    pickle.dump(listOfIndividuals, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/individuals.pickle\", \"rb\") as file:\n",
    "    listOfIndividuals = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/SEIRS_model.pickle\", \"rb\") as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'EdgeDataView' object is not subscriptable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ab4a9e83792e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# constant time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0medges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'EdgeDataView' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Format of @param commands positive or negative values\n",
    "Protocol: Social distancing is two way (ie. Interactions will only occur if both agree to it). If one does not agree to it, then it will not occur. \n",
    "\"\"\"\n",
    "def edgeOperation(graph, individuals, commands):\n",
    "    nodeList = list(graph.nodes)\n",
    "    for id, command in enumerate(commands):\n",
    "        individual = individuals[id]\n",
    "        if command > 0: # add edges\n",
    "            for other in individual.connections:\n",
    "                if other not in nodeList: # node has been removed from the graph\n",
    "                    continue\n",
    "                if other.pendingActiveConnections > 0:\n",
    "                    graph.add\n",
    "            pass\n",
    "        if command < 0: # remove edges\n",
    "            pass\n",
    "    return graph\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "@returns : percentage increase \n",
    "\"\"\"    \n",
    "def incomefunction(income):\n",
    "    pass\n",
    "\n",
    "\"\"\"\n",
    "Purpose: Do an action on a set of relevant individuals. \n",
    "@returns : a new version of the graph\n",
    "\"\"\"\n",
    "def stimulusCheck(graph):\n",
    "    pass\n",
    "\n",
    "def getLaidOff(graph):\n",
    "    pass\n",
    "\n",
    "\n",
    "simulations = [stimulusCheck, getLaidOff]\n",
    "\n",
    "\"\"\"\n",
    "@param action       : This is the function that will be run every iteration on the graph\n",
    "@param iterations   : The number of iterations the simulation will be run for\n",
    "@param unit_time    : The amount of time each iteration will run for\n",
    "\"\"\"\n",
    "def runSimulation(action, iterations, unit_time): # this action will be taken every round\n",
    "    with open(\"pickles/SEIRS_model.pickle\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    graph = model.G\n",
    "    for _ in range(iterations):\n",
    "        graph = action(graph)\n",
    "        model.update_G(graph) # update the graph with modified edges\n",
    "        model.run(T=unit_time)\n",
    "\n",
    "edges = model.G.edges([0]) # constant time\n",
    "edges\n",
    "# variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "t = 0.63\nt = 10.10\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit19303f81052b4846ae9ed3e254df4422",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}